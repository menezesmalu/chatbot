{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "from os import supports_follow_symlinks\n",
    "import nltk\n",
    "import csv\n",
    "import pathlib\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "file_list = ['train', 'test','dev']\n",
    "subject = ['Movies_1', 'Movies_2', 'Movies_3']"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dgmneto/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "list_entities = {\"\":[]}\n",
    "def get_entities(frames):\n",
    "    for frame in frames:\n",
    "        for action in frame['actions']:\n",
    "            if action['slot'] == 'intent':\n",
    "                continue\n",
    "            values = action['values']\n",
    "            for value in values:\n",
    "                entity = action['slot']\n",
    "                if entity not in list_entities:\n",
    "                    list_entities[entity] = []\n",
    "                list_entities[entity].append(value)\n",
    "                \n",
    "def get_entity_list(json_file):\n",
    "    phrase_to_entities = []\n",
    "    for item in json_file:\n",
    "        if len(item['services']) > 1 or not np.any(np.in1d(subject, item['services'])):\n",
    "            continue\n",
    "        for turn in item['turns']:\n",
    "            if turn['speaker'] == 'SYSTEM':\n",
    "                continue\n",
    "            splitted_text = nltk.word_tokenize(turn['utterance'])\n",
    "            get_entities(turn['frames'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "for file_name in file_list:\n",
    "    for path in pathlib.Path(f'../dstc8-schema-guided-dialogue/{file_name}').iterdir():\n",
    "        if path.is_file() and not path.match('*schema.json'):\n",
    "            file = open(path, 'r')\n",
    "            json_file = json.loads(file.read())\n",
    "            get_entity_list(json_file)\n",
    "    file.close()\n",
    "for entity in list_entities:\n",
    "    set_values = set(list_entities[entity])\n",
    "    for value in set_values:\n",
    "        f = open(f'./extraction_rasa/{entity}_rasa.txt', 'a')\n",
    "        f.write(str(value + '\\n'))\n",
    "        f.close()\n",
    "        \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('rasa': venv)"
  },
  "interpreter": {
   "hash": "7691df47c0bbc440ab587bfe29eb6fb80aac383addebf33edec5230c95e6d62b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}